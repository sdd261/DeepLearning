{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyMHZHrUtKZmB10J42z9pBpK",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sdd261/DeepLearning/blob/main/research(noisedata).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Import necessary libraries\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.datasets import cifar10\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense\n",
        "from tensorflow.keras.optimizers import Adam\n"
      ],
      "metadata": {
        "id": "dpmyKNYAKxxi"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 1: Load and Preprocess CIFAR-10 Dataset\n",
        "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FaAP34XUK17i",
        "outputId": "1919bd76-f12f-4404-d5ce-85d57b3adc39"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
            "\u001b[1m170498071/170498071\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Normalize the data (to range [0, 1])\n",
        "x_train = x_train.astype('float32') / 255.0\n",
        "x_test = x_test.astype('float32') / 255.0"
      ],
      "metadata": {
        "id": "tJZKQCTUK5mP"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 2: Introduce Noise into Labels\n",
        "def introduce_noise(labels, noise_level=0.2):\n",
        "    \"\"\"Function to introduce noise in a certain percentage of labels.\"\"\"\n",
        "    num_samples = labels.shape[0]\n",
        "    num_noisy = int(noise_level * num_samples)\n",
        "\n",
        "    # Randomly choose indices to corrupt\n",
        "    noisy_indices = np.random.choice(num_samples, num_noisy, replace=False)\n",
        "\n",
        "    # Generate noisy labels\n",
        "    noisy_labels = np.random.randint(0, 10, size=num_noisy)\n",
        "\n",
        "    # Replace original labels with noisy ones\n",
        "    labels[noisy_indices] = noisy_labels.reshape(-1, 1)\n",
        "\n",
        "    return labels\n",
        "\n",
        "# Introduce 20% noise into the training labels\n",
        "y_train_noisy = introduce_noise(np.copy(y_train), noise_level=0.2)"
      ],
      "metadata": {
        "id": "rJJ_iXAgLF3m"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Step 3: One-Hot Encoding of Labels\n",
        "# Ensure labels are in the correct shape (convert from 2D array to 1D array)\n",
        "y_train_noisy_flat = np.squeeze(y_train_noisy)\n",
        "y_test_flat = np.squeeze(y_test)\n"
      ],
      "metadata": {
        "id": "pevw37bTLJtk"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# One-Hot Encoding of Labels\n",
        "y_train_noisy_onehot = to_categorical(y_train_noisy_flat, num_classes=10)\n",
        "y_test_onehot = to_categorical(y_test_flat, num_classes=10)"
      ],
      "metadata": {
        "id": "sWNA6PcHLLHF"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Step 4: Build the CNN Model\n",
        "def create_cnn_model(input_shape=(32, 32, 3), num_classes=10):\n",
        "    \"\"\"Function to create a simple CNN model.\"\"\"\n",
        "    model = Sequential([\n",
        "        Conv2D(32, (3, 3), activation='relu', input_shape=input_shape),\n",
        "        MaxPooling2D((2, 2)),\n",
        "        Conv2D(64, (3, 3), activation='relu'),\n",
        "        MaxPooling2D((2, 2)),\n",
        "        Conv2D(128, (3, 3), activation='relu'),\n",
        "        MaxPooling2D((2, 2)),\n",
        "        Flatten(),\n",
        "        Dense(256, activation='relu'),\n",
        "        Dense(num_classes, activation='softmax')\n",
        "    ])\n",
        "    return model\n"
      ],
      "metadata": {
        "id": "d1JarMATLRzD"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 5: Compile the CNN Model\n",
        "cnn_model = create_cnn_model()\n",
        "cnn_model.compile(optimizer=Adam(), loss='categorical_crossentropy', metrics=['accuracy'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o2fdcgGLLWRQ",
        "outputId": "a52a89c4-f6dd-4ea5-d02b-892693ea46ca"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 6: Train the CNN Model\n",
        "cnn_model.fit(x_train, y_train_noisy_onehot, epochs=50, batch_size=64, validation_data=(x_test, y_test_onehot))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vyZZizJUMD_I",
        "outputId": "d8b8d98b-0ef5-4f96-cc6e-1bcfdece0661"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 11ms/step - accuracy: 0.2631 - loss: 2.0356 - val_accuracy: 0.5341 - val_loss: 1.3979\n",
            "Epoch 2/50\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.4518 - loss: 1.6834 - val_accuracy: 0.6035 - val_loss: 1.2179\n",
            "Epoch 3/50\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.5130 - loss: 1.5602 - val_accuracy: 0.6080 - val_loss: 1.2020\n",
            "Epoch 4/50\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - accuracy: 0.5443 - loss: 1.4887 - val_accuracy: 0.6431 - val_loss: 1.1226\n",
            "Epoch 5/50\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - accuracy: 0.5692 - loss: 1.4303 - val_accuracy: 0.6455 - val_loss: 1.0931\n",
            "Epoch 6/50\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.5904 - loss: 1.3776 - val_accuracy: 0.6634 - val_loss: 1.0536\n",
            "Epoch 7/50\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.6131 - loss: 1.3177 - val_accuracy: 0.6600 - val_loss: 1.0476\n",
            "Epoch 8/50\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - accuracy: 0.6317 - loss: 1.2522 - val_accuracy: 0.6635 - val_loss: 1.0353\n",
            "Epoch 9/50\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.6405 - loss: 1.2169 - val_accuracy: 0.6553 - val_loss: 1.0806\n",
            "Epoch 10/50\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - accuracy: 0.6578 - loss: 1.1687 - val_accuracy: 0.6686 - val_loss: 1.0248\n",
            "Epoch 11/50\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - accuracy: 0.6660 - loss: 1.1211 - val_accuracy: 0.6670 - val_loss: 1.0536\n",
            "Epoch 12/50\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.6856 - loss: 1.0572 - val_accuracy: 0.6476 - val_loss: 1.0875\n",
            "Epoch 13/50\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.6954 - loss: 1.0196 - val_accuracy: 0.6502 - val_loss: 1.0965\n",
            "Epoch 14/50\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.7103 - loss: 0.9639 - val_accuracy: 0.6396 - val_loss: 1.1345\n",
            "Epoch 15/50\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.7281 - loss: 0.9018 - val_accuracy: 0.6279 - val_loss: 1.1759\n",
            "Epoch 16/50\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.7371 - loss: 0.8654 - val_accuracy: 0.6215 - val_loss: 1.2074\n",
            "Epoch 17/50\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - accuracy: 0.7541 - loss: 0.8113 - val_accuracy: 0.6160 - val_loss: 1.2452\n",
            "Epoch 18/50\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.7688 - loss: 0.7505 - val_accuracy: 0.6147 - val_loss: 1.2683\n",
            "Epoch 19/50\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.7823 - loss: 0.6932 - val_accuracy: 0.5893 - val_loss: 1.3904\n",
            "Epoch 20/50\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - accuracy: 0.8010 - loss: 0.6455 - val_accuracy: 0.5845 - val_loss: 1.4378\n",
            "Epoch 21/50\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.8124 - loss: 0.5980 - val_accuracy: 0.5682 - val_loss: 1.5623\n",
            "Epoch 22/50\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - accuracy: 0.8274 - loss: 0.5432 - val_accuracy: 0.5829 - val_loss: 1.5590\n",
            "Epoch 23/50\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.8347 - loss: 0.5130 - val_accuracy: 0.5782 - val_loss: 1.6491\n",
            "Epoch 24/50\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - accuracy: 0.8484 - loss: 0.4694 - val_accuracy: 0.5614 - val_loss: 1.7735\n",
            "Epoch 25/50\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.8585 - loss: 0.4343 - val_accuracy: 0.5790 - val_loss: 1.8327\n",
            "Epoch 26/50\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.8751 - loss: 0.3848 - val_accuracy: 0.5532 - val_loss: 1.9865\n",
            "Epoch 27/50\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - accuracy: 0.8800 - loss: 0.3694 - val_accuracy: 0.5706 - val_loss: 2.0041\n",
            "Epoch 28/50\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - accuracy: 0.8889 - loss: 0.3372 - val_accuracy: 0.5572 - val_loss: 2.2035\n",
            "Epoch 29/50\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.9016 - loss: 0.3012 - val_accuracy: 0.5623 - val_loss: 2.2346\n",
            "Epoch 30/50\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - accuracy: 0.9038 - loss: 0.2850 - val_accuracy: 0.5592 - val_loss: 2.3381\n",
            "Epoch 31/50\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - accuracy: 0.9044 - loss: 0.2808 - val_accuracy: 0.5496 - val_loss: 2.4835\n",
            "Epoch 32/50\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.9195 - loss: 0.2390 - val_accuracy: 0.5504 - val_loss: 2.5332\n",
            "Epoch 33/50\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - accuracy: 0.9215 - loss: 0.2306 - val_accuracy: 0.5505 - val_loss: 2.6629\n",
            "Epoch 34/50\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.9316 - loss: 0.2045 - val_accuracy: 0.5297 - val_loss: 2.7304\n",
            "Epoch 35/50\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - accuracy: 0.9300 - loss: 0.2055 - val_accuracy: 0.5544 - val_loss: 2.8087\n",
            "Epoch 36/50\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.9322 - loss: 0.1965 - val_accuracy: 0.5473 - val_loss: 2.9753\n",
            "Epoch 37/50\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - accuracy: 0.9322 - loss: 0.1931 - val_accuracy: 0.5405 - val_loss: 3.0403\n",
            "Epoch 38/50\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - accuracy: 0.9376 - loss: 0.1795 - val_accuracy: 0.5477 - val_loss: 3.1024\n",
            "Epoch 39/50\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - accuracy: 0.9379 - loss: 0.1812 - val_accuracy: 0.5413 - val_loss: 3.1562\n",
            "Epoch 40/50\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.9395 - loss: 0.1702 - val_accuracy: 0.5424 - val_loss: 3.3261\n",
            "Epoch 41/50\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - accuracy: 0.9438 - loss: 0.1643 - val_accuracy: 0.5300 - val_loss: 3.3675\n",
            "Epoch 42/50\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - accuracy: 0.9422 - loss: 0.1650 - val_accuracy: 0.5323 - val_loss: 3.4385\n",
            "Epoch 43/50\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - accuracy: 0.9486 - loss: 0.1454 - val_accuracy: 0.5259 - val_loss: 3.6102\n",
            "Epoch 44/50\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.9451 - loss: 0.1586 - val_accuracy: 0.5369 - val_loss: 3.5854\n",
            "Epoch 45/50\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - accuracy: 0.9464 - loss: 0.1537 - val_accuracy: 0.5408 - val_loss: 3.6541\n",
            "Epoch 46/50\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - accuracy: 0.9475 - loss: 0.1483 - val_accuracy: 0.5331 - val_loss: 3.7612\n",
            "Epoch 47/50\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.9514 - loss: 0.1398 - val_accuracy: 0.5398 - val_loss: 3.8595\n",
            "Epoch 48/50\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - accuracy: 0.9491 - loss: 0.1457 - val_accuracy: 0.5402 - val_loss: 3.8898\n",
            "Epoch 49/50\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.9472 - loss: 0.1550 - val_accuracy: 0.5238 - val_loss: 4.0444\n",
            "Epoch 50/50\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.9526 - loss: 0.1350 - val_accuracy: 0.5329 - val_loss: 4.0330\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.history.History at 0x7ef87cee0b20>"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 7: Evaluate the Model\n",
        "test_loss, test_acc = cnn_model.evaluate(x_test, y_test_onehot, verbose=2)\n",
        "print(f\"Test accuracy on noisy labels: {test_acc}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-DNtDWmsMtFt",
        "outputId": "433f2d58-2743-43eb-dd28-859af91f7c8e"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "313/313 - 1s - 4ms/step - accuracy: 0.5329 - loss: 4.0330\n",
            "Test accuracy on noisy labels: 0.5328999757766724\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        " In this experiment, 20% of the training labels were deliberately corrupted with random incorrect values. Training a model on noisy data typically leads to a drop in accuracy because the model is learning from incorrect information. Achieving 53.29% accuracy in such a scenario means the model still generalizes reasonably well despite the label noise."
      ],
      "metadata": {
        "id": "u73m0TyfN3e5"
      }
    }
  ]
}